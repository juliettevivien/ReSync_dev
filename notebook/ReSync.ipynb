{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 1 : Import necessary functions, set parameters and load your own recordings ####"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import all the librairies and functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation of librairies and functions\n",
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sys 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:14:58) [MSC v.1929 64 bit (AMD64)]\n",
      "pandas 1.5.3\n",
      "numpy 1.23.5\n",
      "mne 1.3.0\n",
      "sci-py 1.10.0\n",
      "matplotlib 3.6.3\n"
     ]
    }
   ],
   "source": [
    "# check some package versions for documentation and reproducibility\n",
    "import sys\n",
    "import mne\n",
    "from matplotlib import __version__ as plt_version\n",
    "import scipy\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "print('mne', mne.__version__)\n",
    "print('sci-py', scipy.__version__)\n",
    "print('matplotlib', plt_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cd_repo_folder():\n",
    "    \"\"\"sets current working directory to main repo folder\"\"\"\n",
    "    cd = os.getcwd()\n",
    "\n",
    "    check = 0\n",
    "\n",
    "    while os.path.basename(cd) != 'ReSync':\n",
    "\n",
    "        cd = os.path.dirname(cd)\n",
    "        check += 1\n",
    "        if check > 10: raise ValueError('Repo path not found')\n",
    "    \n",
    "    os.chdir(cd)\n",
    "\n",
    "    print(f'working directory changed to {os.getcwd()}')\n",
    "\n",
    "    return os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working directory changed to c:\\Users\\Juliette\\Research\\Projects\\Synchronization_project\\Code\\ReSync\n"
     ]
    }
   ],
   "source": [
    "project_path = set_cd_repo_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import custom-made functions\n",
    "import functions.preprocessing as preproc\n",
    "import functions.utils as utils\n",
    "import functions.plotting as plot\n",
    "import functions.find_artefacts as artefact\n",
    "import functions.crop as crop\n",
    "import functions.main_resync as resync\n",
    "#import functions.plotting_interactive as plot_interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions.plotting_interactive' from 'c:\\\\Users\\\\Juliette\\\\Research\\\\Projects\\\\Synchronization_project\\\\Code\\\\ReSync\\\\functions\\\\plotting_interactive.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(plot)\n",
    "importlib.reload(preproc)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(artefact)\n",
    "importlib.reload(crop)\n",
    "importlib.reload(resync)\n",
    "#importlib.reload(plot_interact)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load your own LFP data:**\n",
    "\n",
    "Resulting variables needed for subsequent analysis:\n",
    "- LFP_array (np.ndarray, multi dimensional): the LFP recording which has to be aligned, containing all channels\n",
    "- lfp_sig (np.ndarray, 1d): the channel containing the LFP signal from the hemisphere where the stimulation was delivered to create artefacts\n",
    "- LFP_rec_ch_names (list): names of all the channels, in a list (will be used to annotate cropped recording)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working dir to go fetch PyPerceive functions:c:\\Users\\Juliette\\Research\\Projects\\Synchronization_project\\Code\\PyPerceive\\code\n",
      "working dir set back to:c:\\Users\\Juliette\\Research\\Projects\\Synchronization_project\\Code\\ReSync\n"
     ]
    }
   ],
   "source": [
    "# load pyPerceive functions\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.chdir(os.path.join(os.getcwd(), 'PyPerceive'))\n",
    "os.chdir(os.path.join(os.getcwd(), 'code'))\n",
    "pyPerceive_path = os.getcwd()\n",
    "print (f'working dir to go fetch PyPerceive functions:{pyPerceive_path}')\n",
    "\n",
    "from PerceiveImport.classes import (\n",
    "    main_class, modality_class, metadata_class,\n",
    "    session_class, condition_class, task_class,\n",
    "    contact_class, run_class\n",
    ")\n",
    "import PerceiveImport.methods.load_rawfile as load_rawfile\n",
    "import PerceiveImport.methods.find_folders as find_folders\n",
    "import PerceiveImport.methods.metadata_helpers as metaHelpers\n",
    "\n",
    "#reset the proper working directory for the analysis\n",
    "os.chdir(project_path)\n",
    "print (f'working dir set back to:{project_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t### WARNING: NaNs in Metadata Table sub-041 ###\n",
      "NaNs in: sub-20220404PStn_ses-2022071206564297_run-BrainSense20220712073400.mat\n",
      "NaNs in: sub-20220404PStn_ses-2022071206564297_run-BrainSense20220712075100.mat\n",
      "NaNs in: sub-20220404PStn_ses-2022071206564297_run-BrainSense20220712080900.mat\n",
      "NaNs in: sub-20220404PStn_ses-2022071206564297_run-BrainSense20220712082700.mat\n",
      "NaNs in: sub-20220404PStn_ses-2022071206564297_run-BrainSense20220712084400.mat\n",
      "add run 1\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=69063\n",
      "    Range : 0 ... 69062 =      0.000 ...   276.248 secs\n",
      "Ready.\n",
      "add run 1\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=78937\n",
      "    Range : 0 ... 78936 =      0.000 ...   315.744 secs\n",
      "Ready.\n",
      "add run 2\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=107625\n",
      "    Range : 0 ... 107624 =      0.000 ...   430.496 secs\n",
      "Ready.\n",
      "add run 3\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=27938\n",
      "    Range : 0 ... 27937 =      0.000 ...   111.748 secs\n",
      "Ready.\n",
      "add run 4\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=37562\n",
      "    Range : 0 ... 37561 =      0.000 ...   150.244 secs\n",
      "Ready.\n",
      "The data object has:\n",
      "\t69063 time samples,\n",
      "\tand a sample frequency of 250.0 Hz\n",
      "\twith a recording duration of 276.252 seconds.\n",
      "\t6 channels were labeled as \n",
      "['LFP_L_13_STN_MT', 'LFP_R_02_STN_MT', 'LFP_L_13_STN_MT_PEAK19Hz_THR20-30_AVG3000ms', 'LFP_R_02_STN_MT_PEAK17Hz_THR20-30_AVG3000ms', 'STIM_L_85Hz_60us', 'STIM_R_85Hz_60us'].\n",
      "The channel containing artefacts has index 0 and is named LFP_L_13_STN_MT\n"
     ]
    }
   ],
   "source": [
    "# choose LFP file\n",
    "sub041 = main_class.PerceiveData(\n",
    "    sub = \"041\", \n",
    "    incl_modalities=['streaming'],\n",
    "    incl_session = [\"fu18m\"],\n",
    "    incl_condition =['m1s0','m1s1'],\n",
    "    incl_task = [\"rest\"],\n",
    "    # incl_contact = [\"RingL\", \"SegmInterR\", \"SegmIntraR\"],\n",
    "    import_json=False,\n",
    "    warn_for_metaNaNs=True,\n",
    "    allow_NaNs_in_metadata=False\n",
    ")\n",
    "\n",
    "# define LFP data\n",
    "LFP_rec = sub041.streaming.fu18m.m1s0.rest.run1.data\n",
    "LFP_array = LFP_rec.get_data()\n",
    "ch_i = 0 #choose index of the channel containing the stim artefacts (O for left hemisphere, 1 for right hemisphere)\n",
    "lfp_sig = LFP_rec.get_data()[ch_i]\n",
    "LFP_rec_ch_names = LFP_rec.ch_names\n",
    "\n",
    "n_chan = len(LFP_rec.ch_names)\n",
    "time_duration_LFP = (LFP_rec.n_times/LFP_rec.info['sfreq']).astype(float)\n",
    "print(     \n",
    "\tf'The data object has:\\n\\t{LFP_rec.n_times} time samples,'      \n",
    "\tf'\\n\\tand a sample frequency of {LFP_rec.info[\"sfreq\"]} Hz'      \n",
    "\tf'\\n\\twith a recording duration of {time_duration_LFP} seconds.'      \n",
    "\tf'\\n\\t{n_chan} channels were labeled as \\n{LFP_rec.ch_names}.')\n",
    "print(f'The channel containing artefacts has index {ch_i} and is named {LFP_rec.ch_names[ch_i]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load your own external data:**\n",
    "(our external data recorder is a TMSi Data recorder.)\n",
    "\n",
    "PM: NOTICE THE POP UP WINDOW AFTER RUNNING, TO SELECT THE FILE LOCATION\n",
    "\n",
    "Resulting variables:\n",
    "- external_file (np.ndarray, multi-dimensional): the complete external recording containing all channels recorded\n",
    "- BIP_channel (np.ndarray, 1d): the channel containing the signal from the bipolar electrode used to pick up the artefacts on the IPG/cable\n",
    "- external_rec_ch_names (list, same length as the number of channels in external_file): list of the channels names, to rename them accordingly after alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions.tmsi_poly5reader as poly5_reader\n",
    "import functions.loading_TMSi as loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file  C:/Users/Juliette/OneDrive - Charité - Universitätsmedizin Berlin/Recordings/TMSi files/sub-041/sub_041_18MFU_M1S0_BrStr_restTap - 20230907T134210/sub_041_18MFU_M1S0_BrStr_restTap-20230907T134210.DATA.Poly5\n",
      "\t Number of samples:  1276704 \n",
      "\t Number of channels:  12 \n",
      "\t Sample rate: 4096 Hz\n",
      "Done reading data.\n",
      "Creating RawArray with float64 data, n_channels=12, n_times=1276704\n",
      "    Range : 0 ... 1276703 =      0.000 ...   311.695 secs\n",
      "Ready.\n",
      "The data object has:\n",
      "\t1276704 time samples,\n",
      "\tand a sample frequency of 4096.0 Hz\n",
      "\twith a recording duration of 311.6953125 seconds.\n",
      "\t12 channels were labeled as \n",
      "['BIP 01', 'BIP 02', 'BIP 03', 'BIP 04', 'X-0', 'Y-0', 'Z-0', 'X-1', 'Y-1', 'Z-1', 'STATUS', 'Counter 2power24'].\n",
      "the channel used to align datas is the channel named BIP 01 and has index 0\n"
     ]
    }
   ],
   "source": [
    "TMSi_data = poly5_reader.Poly5Reader()  # open TMSi data from poly5\n",
    "(BIP_channel,\n",
    " external_file,\n",
    " external_rec_ch_names) = loading.load_TMSi_artefact_channel(TMSi_data) # function adapted for our own data recorder, \n",
    "# to load all necessary variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**READ ME**\n",
    "\n",
    "Before starting the run_resync function, be careful to check that the config file is properly set. In particular, pay attention to:\n",
    "- write the proper subject ID (to not overwrite previous analysis)\n",
    "- write the correct sampling frequencies corresponding to YOUR recordings\n",
    "- by default use kernel \"1\", and set \"real_index_LFP\" to 0 for the first run. This can be adjusted if necessary before re-running.\n",
    "- by default, set \"consider_first_seconds_LFP\", \"consider_first_seconds_external\" and \"ignore_first_seconds_external\" to null. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 2: Align recordings: ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.712695015282861e-11\n",
      "Alignment performed ! \n",
      "Please check carefully in all figures that the samples selected \n",
      "as start of the artefact are correct, and if they are not \n",
      "please correct parameters accordingly in the config file before re-running\n"
     ]
    }
   ],
   "source": [
    "(LFP_df_offset, \n",
    " external_df_offset) = resync.run_resync(\n",
    "    LFP_array=LFP_array,\n",
    "    lfp_sig=lfp_sig,\n",
    "    LFP_rec_ch_names=LFP_rec_ch_names,\n",
    "    external_file=external_file,\n",
    "    BIP_channel=BIP_channel,\n",
    "    external_rec_ch_names=external_rec_ch_names,\n",
    "    SHOW_FIGURES = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 3 : Look for timeshift ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resync.run_timeshift_analysis(\n",
    "    LFP_df_offset,\n",
    "    external_df_offset,\n",
    "    SHOW_FIGURES = True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d88ae3f494ed6750ac12c087146162cb95510d20525109b4b9e2bae86cf73368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

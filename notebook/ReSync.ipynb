{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 1 : Load the recordings, find artefacts, resync ####"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import all the librairies and functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation of librairies and functions\n",
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sys 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:14:58) [MSC v.1929 64 bit (AMD64)]\n",
      "pandas 1.5.3\n",
      "numpy 1.23.5\n",
      "mne 1.3.0\n",
      "sci-py 1.10.0\n",
      "matplotlib 3.6.3\n"
     ]
    }
   ],
   "source": [
    "# check some package versions for documentation and reproducibility\n",
    "import sys\n",
    "import mne\n",
    "from matplotlib import __version__ as plt_version\n",
    "import scipy\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "print('mne', mne.__version__)\n",
    "print('sci-py', scipy.__version__)\n",
    "print('matplotlib', plt_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cd_repo_folder():\n",
    "    \"\"\"sets current working directory to main repo folder\"\"\"\n",
    "    cd = os.getcwd()\n",
    "\n",
    "    check = 0\n",
    "\n",
    "    while os.path.basename(cd) != 'ReSync':\n",
    "\n",
    "        cd = os.path.dirname(cd)\n",
    "        check += 1\n",
    "        if check > 10: raise ValueError('Repo path not found')\n",
    "    \n",
    "    os.chdir(cd)\n",
    "\n",
    "    print(f'working directory changed to {os.getcwd()}')\n",
    "\n",
    "    return os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working directory changed to c:\\Users\\Juliette\\Research\\Projects\\Synchronization_project\\Code\\ReSync\n"
     ]
    }
   ],
   "source": [
    "project_path = set_cd_repo_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import custom-made functions\n",
    "import functions.preprocessing as preproc\n",
    "import functions.utils as utils\n",
    "import functions.plotting as plot\n",
    "import functions.find_artefacts as artefact\n",
    "import functions.crop as crop\n",
    "import functions.main_resync as resync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions.main_resync' from 'c:\\\\Users\\\\Juliette\\\\Research\\\\Projects\\\\Synchronization_project\\\\Code\\\\ReSync\\\\functions\\\\main_resync.py'>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(plot)\n",
    "importlib.reload(preproc)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(artefact)\n",
    "importlib.reload(crop)\n",
    "importlib.reload(resync)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load your own LFP data:**\n",
    "\n",
    "Resulting variables needed for subsequent analysis:\n",
    "- LFP_array (np.ndarray, multi dimensional): the LFP recording which has to be aligned, containing all channels\n",
    "- lfp_sig (np.ndarray, 1d): the channel containing the LFP signal from the hemisphere where the stimulation was delivered to create artefacts\n",
    "- sf_LFP (int): the sampling frequency of the LFP signal\n",
    "- LFP_rec_ch_names (list): names of all the channels, in a list (will be used to annotate cropped recording)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working dir to go fetch PyPerceive functions:c:\\Users\\Juliette\\Research\\Projects\\Synchronization_project\\Code\\PyPerceive\\code\n",
      "working dir set back to:c:\\Users\\Juliette\\Research\\Projects\\Synchronization_project\\Code\\ReSync\n"
     ]
    }
   ],
   "source": [
    "# load pyPerceive functions\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.chdir(os.path.join(os.getcwd(), 'PyPerceive'))\n",
    "os.chdir(os.path.join(os.getcwd(), 'code'))\n",
    "pyPerceive_path = os.getcwd()\n",
    "print (f'working dir to go fetch PyPerceive functions:{pyPerceive_path}')\n",
    "\n",
    "from PerceiveImport.classes import (\n",
    "    main_class, modality_class, metadata_class,\n",
    "    session_class, condition_class, task_class,\n",
    "    contact_class, run_class\n",
    ")\n",
    "import PerceiveImport.methods.load_rawfile as load_rawfile\n",
    "import PerceiveImport.methods.find_folders as find_folders\n",
    "import PerceiveImport.methods.metadata_helpers as metaHelpers\n",
    "\n",
    "#reset the proper working directory for the analysis\n",
    "os.chdir(project_path)\n",
    "print (f'working dir set back to:{project_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t### WARNING: NaNs in Metadata Table sub-048 ###\n",
      "NaNs in: sub-20220530PStn_ses-2023060807082685_run-IS20230608072000.mat\n",
      "NaNs in: sub-20220530PStn_ses-2023060809351485_run-IS20230608095000.mat\n",
      "add run 1\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=67500\n",
      "    Range : 0 ... 67499 =      0.000 ...   269.996 secs\n",
      "Ready.\n",
      "add run 1\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=224188\n",
      "    Range : 0 ... 224187 =      0.000 ...   896.748 secs\n",
      "Ready.\n",
      "add run 1\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=70500\n",
      "    Range : 0 ... 70499 =      0.000 ...   281.996 secs\n",
      "Ready.\n",
      "add run 1\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=213500\n",
      "    Range : 0 ... 213499 =      0.000 ...   853.996 secs\n",
      "Ready.\n",
      "The data object has:\n",
      "\t67500 time samples,\n",
      "\tand a sample frequency of 250.0 Hz\n",
      "\twith a recording duration of 270.0 seconds.\n",
      "\t6 channels were labeled as \n",
      "['LFP_L_13_STN_MT', 'LFP_R_02_STN_MT', 'LFP_L_13_STN_MT_PEAK15Hz_THR20-30_AVG3000ms', 'LFP_R_02_STN_MT_PEAK8Hz_THR20-30_AVG3000ms', 'STIM_L_125Hz_40us', 'STIM_R_125Hz_40us'].\n",
      "The channel containing artefacts has index 0 and is named LFP_L_13_STN_MT\n"
     ]
    }
   ],
   "source": [
    "# choose LFP file\n",
    "sub048 = main_class.PerceiveData(\n",
    "    sub = \"048\", \n",
    "    incl_modalities=['streaming'],\n",
    "    incl_session = [\"fu12m\"],\n",
    "    incl_condition =['m0s0','m0s1','m1s0','m1s1'],\n",
    "    incl_task = [\"rest\"],\n",
    "    # incl_contact = [\"RingL\", \"SegmInterR\", \"SegmIntraR\"],\n",
    "    import_json=False,\n",
    "    warn_for_metaNaNs=True,\n",
    "    allow_NaNs_in_metadata=False\n",
    ")\n",
    "\n",
    "# define LFP data\n",
    "LFP_rec = sub048.streaming.fu12m.m0s0.rest.run1.data\n",
    "LFP_array = LFP_rec.get_data()\n",
    "ch_i = 0 #choose index of the channel containing the stim artefacts (O for left hemisphere, 1 for right hemisphere)\n",
    "lfp_sig = LFP_rec.get_data()[ch_i]\n",
    "LFP_rec_ch_names = LFP_rec.ch_names\n",
    "#sf_LFP = round(LFP_rec.info['sfreq']) will be deleted and put in settings\n",
    "\n",
    "n_chan = len(LFP_rec.ch_names)\n",
    "time_duration_LFP = (LFP_rec.n_times/LFP_rec.info['sfreq']).astype(float)\n",
    "print(     \n",
    "\tf'The data object has:\\n\\t{LFP_rec.n_times} time samples,'      \n",
    "\tf'\\n\\tand a sample frequency of {LFP_rec.info[\"sfreq\"]} Hz'      \n",
    "\tf'\\n\\twith a recording duration of {time_duration_LFP} seconds.'      \n",
    "\tf'\\n\\t{n_chan} channels were labeled as \\n{LFP_rec.ch_names}.')\n",
    "print(f'The channel containing artefacts has index {ch_i} and is named {LFP_rec.ch_names[ch_i]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load your own external data:**\n",
    "(our external data recorder is a TMSi Data recorder.)\n",
    "\n",
    "PM: NOTICE THE POP UP WINDOW AFTER RUNNING, TO SELECT THE FILE LOCATION\n",
    "\n",
    "Resulting variables:\n",
    "- BIP_channel (np.ndarray, 1d): the channel containing the signal from the bipolar electrode used to pick up the artefacts on the IPG/cable\n",
    "- external_file (np.ndarray, multi-dimensional): the complete external recording containing all channels recorded\n",
    "- external_rec_ch_names (list, same length as the number of channels in external_file): list of the channels names, to rename them accordingly after alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions.tmsi_poly5reader as poly5_reader\n",
    "import functions.loading_TMSi as loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions.loading_TMSi' from 'c:\\\\Users\\\\Juliette\\\\Research\\\\Projects\\\\Synchronization_project\\\\Code\\\\ReSync\\\\functions\\\\loading_TMSi.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file  C:/Users/Juliette/OneDrive - Charité - Universitätsmedizin Berlin/Recordings/TMSi files/sub-048/12MFU/sub048_12mfu_M0S0_BrStr_RestTap - 20230608T093010/sub048_12mfu_M0S0_BrStr_RestTap-20230608T093010.DATA.Poly5\n",
      "\t Number of samples:  1168895 \n",
      "\t Number of channels:  9 \n",
      "\t Sample rate: 4000 Hz\n",
      "Done reading data.\n",
      "Creating RawArray with float64 data, n_channels=9, n_times=1168895\n",
      "    Range : 0 ... 1168894 =      0.000 ...   292.224 secs\n",
      "Ready.\n",
      "The data object has:\n",
      "\t1168895 time samples,\n",
      "\tand a sample frequency of 4000.0 Hz\n",
      "\twith a recording duration of 292.22375 seconds.\n",
      "\t9 channels were labeled as \n",
      "['BIP 01', 'X-0', 'Y-0', 'Z-0', 'X-1', 'Y-1', 'Z-1', 'STATUS', 'Counter 2power24'].\n",
      "the channel used to align datas is the channel named BIP 01 and has index 0\n"
     ]
    }
   ],
   "source": [
    "TMSi_data = poly5_reader.Poly5Reader()  # open TMSi data from poly5\n",
    "(BIP_channel,\n",
    " external_file,\n",
    " external_rec_ch_names) = loading.load_TMSi_artefact_channel(TMSi_data) # function adapted for our own data recorder, \n",
    "# to load all necessary variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Align recordings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment successful! \n",
      "Please check carefully in all figures that the samples selected \n",
      "as start of the artefact are correct, and if they are not \n",
      "please correct parameters accordingly in the config file before re-running\n"
     ]
    }
   ],
   "source": [
    "(LFP_df_offset, \n",
    " external_df_offset) = resync.run_resync(\n",
    "    LFP_array=LFP_array,\n",
    "    lfp_sig=lfp_sig,\n",
    "    LFP_rec_ch_names=LFP_rec_ch_names,\n",
    "    external_file=external_file,\n",
    "    BIP_channel=BIP_channel,\n",
    "    external_rec_ch_names=external_rec_ch_names,\n",
    "    SHOW_FIGURES = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 2 : Look for timeshift ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeshift analysis performed! \n",
      "The result is: 3.4999999999740794 ms delay at the last detected artefact, \n",
      "after a recording duration of 258.612s.\n"
     ]
    }
   ],
   "source": [
    "resync.run_timeshift_analysis(\n",
    "    LFP_df_offset,\n",
    "    external_df_offset,\n",
    "    SHOW_FIGURES = False\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d88ae3f494ed6750ac12c087146162cb95510d20525109b4b9e2bae86cf73368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

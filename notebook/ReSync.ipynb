{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 1 : Load the recordings, find artefacts, resync ####"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import all the librairies and functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation of librairies and functions\n",
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sys 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:14:58) [MSC v.1929 64 bit (AMD64)]\n",
      "pandas 1.5.3\n",
      "numpy 1.23.5\n",
      "mne 1.3.0\n",
      "sci-py 1.10.0\n",
      "matplotlib 3.6.3\n"
     ]
    }
   ],
   "source": [
    "# check some package versions for documentation and reproducibility\n",
    "import sys\n",
    "import mne\n",
    "from matplotlib import __version__ as plt_version\n",
    "import scipy\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "print('mne', mne.__version__)\n",
    "print('sci-py', scipy.__version__)\n",
    "print('matplotlib', plt_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cd_repo_folder():\n",
    "    \"\"\"sets current working directory to main repo folder\"\"\"\n",
    "    cd = os.getcwd()\n",
    "\n",
    "    check = 0\n",
    "\n",
    "    while os.path.basename(cd) != 'ReSync':\n",
    "\n",
    "        cd = os.path.dirname(cd)\n",
    "        check += 1\n",
    "        if check > 10: raise ValueError('Repo path not found')\n",
    "    \n",
    "    os.chdir(cd)\n",
    "\n",
    "    print(f'working directory changed to {os.getcwd()}')\n",
    "\n",
    "    return os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working directory changed to c:\\Users\\Juliette\\Research\\Projects\\Synchronization_project\\Code\\ReSync\n"
     ]
    }
   ],
   "source": [
    "project_path = set_cd_repo_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import custom-made functions\n",
    "import functions.preprocessing as preproc\n",
    "import functions.utils as utils\n",
    "import functions.plotting as plot\n",
    "import functions.find_artefacts as artefact\n",
    "import functions.crop as crop\n",
    "import functions.main_resync as resync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions.main_resync' from 'c:\\\\Users\\\\Juliette\\\\Research\\\\Projects\\\\Synchronization_project\\\\Code\\\\ReSync\\\\functions\\\\main_resync.py'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(plot)\n",
    "importlib.reload(preproc)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(artefact)\n",
    "importlib.reload(crop)\n",
    "importlib.reload(resync)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load your own LFP data:**\n",
    "\n",
    "Resulting variables needed for subsequent analysis:\n",
    "- LFP_array (np.ndarray, multi dimensional): the LFP recording which has to be aligned, containing all channels\n",
    "- lfp_sig (np.ndarray, 1d): the channel containing the LFP signal from the hemisphere where the stimulation was delivered to create artefacts\n",
    "- sf_LFP (int): the sampling frequency of the LFP signal\n",
    "- LFP_rec_ch_names (list): names of all the channels, in a list (will be used to annotate cropped recording)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working dir to go fetch PyPerceive functions:c:\\Users\\Juliette\\Research\\Projects\\Synchronization_project\\Code\\PyPerceive\\code\n",
      "working dir set back to:c:\\Users\\Juliette\\Research\\Projects\\Synchronization_project\\Code\\ReSync\n"
     ]
    }
   ],
   "source": [
    "# load pyPerceive functions\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.chdir(os.path.join(os.getcwd(), 'PyPerceive'))\n",
    "os.chdir(os.path.join(os.getcwd(), 'code'))\n",
    "pyPerceive_path = os.getcwd()\n",
    "print (f'working dir to go fetch PyPerceive functions:{pyPerceive_path}')\n",
    "\n",
    "from PerceiveImport.classes import (\n",
    "    main_class, modality_class, metadata_class,\n",
    "    session_class, condition_class, task_class,\n",
    "    contact_class, run_class\n",
    ")\n",
    "import PerceiveImport.methods.load_rawfile as load_rawfile\n",
    "import PerceiveImport.methods.find_folders as find_folders\n",
    "import PerceiveImport.methods.metadata_helpers as metaHelpers\n",
    "\n",
    "#reset the proper working directory for the analysis\n",
    "os.chdir(project_path)\n",
    "print (f'working dir set back to:{project_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t### WARNING: NaNs in Metadata Table sub-048 ###\n",
      "NaNs in: sub-20220530PStn_ses-2023060807082685_run-IS20230608072000.mat\n",
      "NaNs in: sub-20220530PStn_ses-2023060809351485_run-IS20230608095000.mat\n",
      "add run 1\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=67500\n",
      "    Range : 0 ... 67499 =      0.000 ...   269.996 secs\n",
      "Ready.\n",
      "add run 1\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=224188\n",
      "    Range : 0 ... 224187 =      0.000 ...   896.748 secs\n",
      "Ready.\n",
      "add run 1\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=70500\n",
      "    Range : 0 ... 70499 =      0.000 ...   281.996 secs\n",
      "Ready.\n",
      "add run 1\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=213500\n",
      "    Range : 0 ... 213499 =      0.000 ...   853.996 secs\n",
      "Ready.\n",
      "The data object has:\n",
      "\t67500 time samples,\n",
      "\tand a sample frequency of 250.0 Hz\n",
      "\twith a recording duration of 270.0 seconds.\n",
      "\t6 channels were labeled as \n",
      "['LFP_L_13_STN_MT', 'LFP_R_02_STN_MT', 'LFP_L_13_STN_MT_PEAK15Hz_THR20-30_AVG3000ms', 'LFP_R_02_STN_MT_PEAK8Hz_THR20-30_AVG3000ms', 'STIM_L_125Hz_40us', 'STIM_R_125Hz_40us'].\n",
      "The channel containing artefacts has index 0 and is named LFP_L_13_STN_MT\n"
     ]
    }
   ],
   "source": [
    "# choose LFP file\n",
    "sub048 = main_class.PerceiveData(\n",
    "    sub = \"048\", \n",
    "    incl_modalities=['streaming'],\n",
    "    incl_session = [\"fu12m\"],\n",
    "    incl_condition =['m0s0','m0s1','m1s0','m1s1'],\n",
    "    incl_task = [\"rest\"],\n",
    "    # incl_contact = [\"RingL\", \"SegmInterR\", \"SegmIntraR\"],\n",
    "    import_json=False,\n",
    "    warn_for_metaNaNs=True,\n",
    "    allow_NaNs_in_metadata=False\n",
    ")\n",
    "\n",
    "# define LFP data\n",
    "LFP_rec = sub048.streaming.fu12m.m0s0.rest.run1.data\n",
    "LFP_array = LFP_rec.get_data()\n",
    "ch_i = 0 #choose index of the channel containing the stim artefacts (O for left hemisphere, 1 for right hemisphere)\n",
    "lfp_sig = LFP_rec.get_data()[ch_i]\n",
    "LFP_rec_ch_names = LFP_rec.ch_names\n",
    "#sf_LFP = round(LFP_rec.info['sfreq']) will be deleted and put in settings\n",
    "\n",
    "n_chan = len(LFP_rec.ch_names)\n",
    "time_duration_LFP = (LFP_rec.n_times/LFP_rec.info['sfreq']).astype(float)\n",
    "print(     \n",
    "\tf'The data object has:\\n\\t{LFP_rec.n_times} time samples,'      \n",
    "\tf'\\n\\tand a sample frequency of {LFP_rec.info[\"sfreq\"]} Hz'      \n",
    "\tf'\\n\\twith a recording duration of {time_duration_LFP} seconds.'      \n",
    "\tf'\\n\\t{n_chan} channels were labeled as \\n{LFP_rec.ch_names}.')\n",
    "print(f'The channel containing artefacts has index {ch_i} and is named {LFP_rec.ch_names[ch_i]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load your own external data:**\n",
    "(our external data recorder is a TMSi Data recorder.)\n",
    "\n",
    "PM: NOTICE THE POP UP WINDOW AFTER RUNNING, TO SELECT THE FILE LOCATION\n",
    "\n",
    "Resulting variables:\n",
    "- BIP_channel (np.ndarray, 1d): the channel containing the signal from the bipolar electrode used to pick up the artefacts on the IPG/cable\n",
    "- external_file (np.ndarray, multi-dimensional): the complete external recording containing all channels recorded\n",
    "- external_rec_ch_names (list, same length as the number of channels in external_file): list of the channels names, to rename them accordingly after alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions.tmsi_poly5reader as poly5_reader\n",
    "import functions.loading_TMSi as loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions.loading_TMSi' from 'c:\\\\Users\\\\Juliette\\\\Research\\\\Projects\\\\Synchronization_project\\\\Code\\\\ReSync\\\\functions\\\\loading_TMSi.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file  C:/Users/Juliette/OneDrive - Charité - Universitätsmedizin Berlin/Recordings/TMSi files/sub-048/12MFU/sub048_12mfu_M0S0_BrStr_RestTap - 20230608T093010/sub048_12mfu_M0S0_BrStr_RestTap-20230608T093010.DATA.Poly5\n",
      "\t Number of samples:  1168895 \n",
      "\t Number of channels:  9 \n",
      "\t Sample rate: 4000 Hz\n",
      "Done reading data.\n",
      "Creating RawArray with float64 data, n_channels=9, n_times=1168895\n",
      "    Range : 0 ... 1168894 =      0.000 ...   292.224 secs\n",
      "Ready.\n",
      "The data object has:\n",
      "\t1168895 time samples,\n",
      "\tand a sample frequency of 4000.0 Hz\n",
      "\twith a recording duration of 292.22375 seconds.\n",
      "\t9 channels were labeled as \n",
      "['BIP 01', 'X-0', 'Y-0', 'Z-0', 'X-1', 'Y-1', 'Z-1', 'STATUS', 'Counter 2power24'].\n",
      "the channel used to align datas is the channel named BIP 01 and has index 0\n"
     ]
    }
   ],
   "source": [
    "TMSi_data = poly5_reader.Poly5Reader()  # open TMSi data from poly5\n",
    "(BIP_channel,\n",
    " external_file,\n",
    " external_rec_ch_names) = loading.load_TMSi_artefact_channel(TMSi_data) # function adapted for our own data recorder, \n",
    "# to load all necessary variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Align recordings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment successful! Please check figures for proper sample selection as start of the artefact, and correct in the config file if necessary before re-running\n"
     ]
    }
   ],
   "source": [
    "(LFP_df_offset, \n",
    " external_df_offset) = resync.run_resync(\n",
    "    LFP_array=LFP_array,\n",
    "    lfp_sig=lfp_sig,\n",
    "    LFP_rec_ch_names=LFP_rec_ch_names,\n",
    "    external_file=external_file,\n",
    "    BIP_channel=BIP_channel,\n",
    "    external_rec_ch_names=external_rec_ch_names,\n",
    "    SHOW_FIGURES = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 2 : Look for timeshift ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m timeshift \u001b[39m=\u001b[39m resync\u001b[39m.\u001b[39;49mrun_timeshift_analysis(\n\u001b[0;32m      2\u001b[0m     LFP_df_offset,\n\u001b[0;32m      3\u001b[0m     external_df_offset,\n\u001b[0;32m      4\u001b[0m     SHOW_FIGURES \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m timeshift\n",
      "File \u001b[1;32mc:\\Users\\Juliette\\Research\\Projects\\Synchronization_project\\Code\\ReSync\\functions\\main_resync.py:364\u001b[0m, in \u001b[0;36mrun_timeshift_analysis\u001b[1;34m(LFP_df_offset, external_df_offset, SHOW_FIGURES)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[39melse\u001b[39;00m: plt\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    360\u001b[0m \u001b[39m### SELECT CORRECT ARTEFACTS ###\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[39m# the algorithm might detect \"artefacts\" that are not really artefacts. \u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[39m# With the images saved, the user can select the ones that are correct \u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[39m# and enter their index in the config.json file.\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m real_art_time_LFP_offset\u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mextract_elements(art_time_LFP_offset,\n\u001b[0;32m    365\u001b[0m                                                  loaded_dict[\u001b[39m'\u001b[39;49m\u001b[39mindex_real_artefacts_LFP\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m    366\u001b[0m ) \n\u001b[0;32m    367\u001b[0m real_art_time_BIP_offset\u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mextract_elements(art_time_BIP_offset, \n\u001b[0;32m    368\u001b[0m                                                  loaded_dict[\u001b[39m'\u001b[39m\u001b[39mindex_real_artefacts_BIP\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    369\u001b[0m )\n\u001b[0;32m    372\u001b[0m \u001b[39m### ASSESS TIMESHIFT ###\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \n\u001b[0;32m    374\u001b[0m \u001b[39m# once the artefacts are all correctly selected, the timeshift can be computed:\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Juliette\\Research\\Projects\\Synchronization_project\\Code\\ReSync\\functions\\utils.py:107\u001b[0m, in \u001b[0;36mextract_elements\u001b[1;34m(data_list, indices_to_extract)\u001b[0m\n\u001b[0;32m    104\u001b[0m getter \u001b[39m=\u001b[39m operator\u001b[39m.\u001b[39mitemgetter(\u001b[39m*\u001b[39mindices_to_extract)\n\u001b[0;32m    106\u001b[0m \u001b[39m# Use the itemgetter to extract the elements from the data_list\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m extracted_elements \u001b[39m=\u001b[39m getter(data_list)\n\u001b[0;32m    109\u001b[0m \u001b[39mreturn\u001b[39;00m extracted_elements\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "timeshift = resync.run_timeshift_analysis(\n",
    "    LFP_df_offset,\n",
    "    external_df_offset,\n",
    "    SHOW_FIGURES = False\n",
    ")\n",
    "\n",
    "timeshift"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d88ae3f494ed6750ac12c087146162cb95510d20525109b4b9e2bae86cf73368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
